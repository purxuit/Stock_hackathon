{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac5ca9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# copy of penalized_linear_hackathon\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485fd81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Display current time (for timing purposes)\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "# Set working directory (adjust as necessary)\n",
    "work_dir = \"C:\\\\Users\\\\Naifu\\\\Desktop\\\\Hackathon\"\n",
    "\n",
    "# Read the sample data\n",
    "file_path = os.path.join(work_dir, \"ret_sample.csv\")\n",
    "chunk_iter = pd.read_csv(file_path, \n",
    "                        parse_dates=[\"ret_eom\"], \n",
    "                        low_memory=False, \n",
    "                        chunksize=500000, # adjust chunksize\n",
    "                        nrows=2_000_000) # only look at first 2M rows\n",
    "\n",
    "# Example: just look at first chunk\n",
    "first_chunk = next(chunk_iter)\n",
    "\n",
    "# Or concatenate processed chunks\n",
    "data_list = []\n",
    "for chunk in chunk_iter:\n",
    "    # do some preprocessing here (filtering, dropping cols)\n",
    "    data_list.append(chunk)\n",
    "raw = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Read the list of stock variables (predictors)\n",
    "file_path = os.path.join(work_dir, \"factor_char_list.csv\")\n",
    "stock_vars = list(pd.read_csv(file_path)[\"variable\"].values)\n",
    "\n",
    "# Define the return variable\n",
    "ret_var = \"stock_ret\"\n",
    "new_set = raw[raw[ret_var].notna()].copy()  # Filter out missing returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af757d0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Rank-transform each stock variable monthly\n",
    "monthly = new_set.groupby(\"date\")\n",
    "data = pd.DataFrame()\n",
    "for date, monthly_raw in monthly:\n",
    "    group = monthly_raw.copy()\n",
    "    for var in stock_vars:\n",
    "        var_median = group[var].median(skipna=True)\n",
    "        group[var] = group[var].fillna(var_median)  # Fill missing values with median\n",
    "        group[var] = group[var].rank(method=\"dense\") - 1\n",
    "        group_max = group[var].max()\n",
    "        if group_max > 0:\n",
    "            group[var] = (group[var] / group_max) * 2 - 1\n",
    "        else:\n",
    "            group[var] = 0  # Handle all missing values\n",
    "            print(f\"Warning: {date} {var} set to zero.\")\n",
    "\n",
    "    # Append the adjusted data\n",
    "    data = pd.concat([data, group], ignore_index=True)\n",
    "\n",
    "# Set initial training start date\n",
    "starting = pd.to_datetime(\"2005-01-01\")\n",
    "counter = 0\n",
    "pred_out = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd816ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Expanding window backtest loop\n",
    "while (starting + pd.DateOffset(years=11 + counter)) <= pd.to_datetime(\"2026-01-01\"):\n",
    "    cutoff = [\n",
    "        starting,\n",
    "        starting + pd.DateOffset(years=8 + counter),  # 8 years for training\n",
    "        starting + pd.DateOffset(years=10 + counter),  # 2 years for validation\n",
    "        starting + pd.DateOffset(years=11 + counter),  # 1 year for testing\n",
    "    ]\n",
    "\n",
    "    # Split the dataset into training, validation, and test sets\n",
    "    train = data[(data[\"date\"] >= cutoff[0]) & (data[\"date\"] < cutoff[1])]\n",
    "    validate = data[(data[\"date\"] >= cutoff[1]) & (data[\"date\"] < cutoff[2])]\n",
    "    test = data[(data[\"date\"] >= cutoff[2]) & (data[\"date\"] < cutoff[3])]\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler().fit(train[stock_vars])\n",
    "    train[stock_vars] = scaler.transform(train[stock_vars])\n",
    "    validate[stock_vars] = scaler.transform(validate[stock_vars])\n",
    "    test[stock_vars] = scaler.transform(test[stock_vars])\n",
    "\n",
    "    # Prepare training, validation, and test sets\n",
    "    X_train = train[stock_vars].values\n",
    "    Y_train = train[ret_var].values\n",
    "    X_val = validate[stock_vars].values\n",
    "    Y_val = validate[ret_var].values\n",
    "    X_test = test[stock_vars].values\n",
    "    Y_test = test[ret_var].values\n",
    "\n",
    "    # Demean the returns\n",
    "    Y_mean = np.mean(Y_train)\n",
    "    Y_train_dm = Y_train - Y_mean\n",
    "\n",
    "    # Linear regression prediction\n",
    "    reg = LinearRegression(fit_intercept=False)\n",
    "    reg.fit(X_train, Y_train_dm)\n",
    "    x_pred = reg.predict(X_test) + Y_mean\n",
    "    reg_pred = test[[\"year\", \"month\", \"ret_eom\", \"id\", ret_var]]\n",
    "    reg_pred[\"ols\"] = x_pred\n",
    "\n",
    "    # Lasso Regression\n",
    "    lambdas = np.arange(-4, 4.1, 0.1)\n",
    "    val_mse = np.zeros(len(lambdas))\n",
    "    for ind, i in enumerate(lambdas):\n",
    "        reg = Lasso(alpha=(10**i), max_iter=1000000, fit_intercept=False)\n",
    "        reg.fit(X_train, Y_train_dm)\n",
    "        val_mse[ind] = mean_squared_error(Y_val, reg.predict(X_val) + Y_mean)\n",
    "\n",
    "    best_lambda = lambdas[np.argmin(val_mse)]\n",
    "    reg = Lasso(alpha=(10**best_lambda), max_iter=1000000, fit_intercept=False)\n",
    "    reg.fit(X_train, Y_train_dm)\n",
    "    x_pred = reg.predict(X_test) + Y_mean\n",
    "    reg_pred[\"lasso\"] = x_pred\n",
    "\n",
    "    # Ridge Regression\n",
    "    lambdas = np.arange(-1, 8.1, 0.1)\n",
    "    val_mse = np.zeros(len(lambdas))\n",
    "    for ind, i in enumerate(lambdas):\n",
    "        reg = Ridge(alpha=(10**i * 0.5), fit_intercept=False)\n",
    "        reg.fit(X_train, Y_train_dm)\n",
    "        val_mse[ind] = mean_squared_error(Y_val, reg.predict(X_val) + Y_mean)\n",
    "\n",
    "    best_lambda = lambdas[np.argmin(val_mse)]\n",
    "    reg = Ridge(alpha=(10**best_lambda * 0.5), fit_intercept=False)\n",
    "    reg.fit(X_train, Y_train_dm)\n",
    "    x_pred = reg.predict(X_test) + Y_mean\n",
    "    reg_pred[\"ridge\"] = x_pred\n",
    "\n",
    "    # ElasticNet Regression\n",
    "    lambdas = np.arange(-4, 4.1, 0.1)\n",
    "    val_mse = np.zeros(len(lambdas))\n",
    "    for ind, i in enumerate(lambdas):\n",
    "        reg = ElasticNet(alpha=(10**i), max_iter=1000000, fit_intercept=False)\n",
    "        reg.fit(X_train, Y_train_dm)\n",
    "        val_mse[ind] = mean_squared_error(Y_val, reg.predict(X_val) + Y_mean)\n",
    "\n",
    "    best_lambda = lambdas[np.argmin(val_mse)]\n",
    "    reg = ElasticNet(alpha=(10**best_lambda), max_iter=1000000, fit_intercept=False)\n",
    "    reg.fit(X_train, Y_train_dm)\n",
    "    x_pred = reg.predict(X_test) + Y_mean\n",
    "    reg_pred[\"en\"] = x_pred\n",
    "\n",
    "    # Append predictions\n",
    "    pred_out = pd.concat([pred_out, reg_pred], ignore_index=True)\n",
    "\n",
    "    # Move to the next year\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e70cd1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Output the predicted values\n",
    "pred_out.to_csv(\"output.csv\", index=False)\n",
    "\n",
    "# Print OOS R2\n",
    "yreal = pred_out[ret_var].values\n",
    "for model_name in [\"ols\", \"lasso\", \"ridge\", \"en\"]:\n",
    "    ypred = pred_out[model_name].values\n",
    "    r2 = 1 - np.sum(np.square((yreal - ypred))) / np.sum(np.square(yreal))\n",
    "    print(model_name, r2)\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
